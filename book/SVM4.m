% This tests the support vector machine content that appears in the book.
% Only the basic plots of the input data and a few contours are provided
% here.  h1, h2, and h3 are the associated figure handles.

% To allow for the low-rank expansion parameter to be set
global GAUSSQR_PARAMETERS

% Initial example for support-vector machines
% This makes sure the same results present each times
if exist('rng','builtin')
    rng(0);
else
    rand('state',0);
    randn('state',0);
end

% Use the low rank matrix multiplication strategy
low_rank = 0;
GAUSSQR_PARAMETERS.DEFAULT_REGRESSION_FUNC = .05;

% Choose a range of ep and bc values
epvec = logspace(-2,2,30);
bcvec = logspace(-2,4,31);

% Choose the number of cross-validations to compute
cv_fold = 10;

% Define our normal distributions
grnmean = [1,0;0,1;2,1];
redmean = [0,0;1,1;2,0];
grnmean_N = size(grnmean,1);
redmean_N = size(redmean,1);
grncov = .5*eye(2);
redcov = .5*eye(2);

% How many points of each model do we want to classify and learn from
grn_test_N = 20;
red_test_N = 20;
grn_train_N = 200;
red_train_N = 200;

% How much fudge factor do we want in our training set
grn_buffer = .2;
red_buffer = .2;

% Generate some manufactured data and attempt to classify it
% The data will be generated by normal distributions with different means
% Half of the data will come from green and half from red
grnpop = mvnrnd(grnmean(randi(grnmean_N,grn_test_N,1),:),repmat(grncov,1,1,grn_test_N),grn_test_N);
redpop = mvnrnd(redmean(randi(redmean_N,red_test_N,1),:),repmat(redcov,1,1,red_test_N),red_test_N);

% Generate a training set from which to learn the classifier
grnpts = zeros(grn_train_N,2);
redpts = zeros(red_train_N,2);
for i = 1:grn_train_N
    grnpts(i,:) = mvnrnd(grnpop(ceil(rand*grn_test_N),:),grncov*grn_buffer);
end
for i = 1:red_train_N
    redpts(i,:) = mvnrnd(redpop(ceil(rand*red_test_N),:),redcov*red_buffer);
end

% Create a vector of data and associated classifications
% Green label 1, red label -1
train_data = [grnpts;redpts];
train_class = ones(grn_train_N+red_train_N,1);
train_class(grn_train_N+1:grn_train_N+red_train_N) = -1;
N_train = length(train_class);
test_data = [grnpop;redpop];
test_class = ones(grn_test_N+red_test_N,1);
test_class(grn_test_N+1:grn_test_N+red_test_N) = -1;
N_test = length(test_class);


% Scatter plot of the input data
h1 = figure;
hold on
plot(grnpop(:,1),grnpop(:,2),'g+','markersize',12)
plot(redpop(:,1),redpop(:,2),'rx','markersize',12)
plot(grnpop(:,1),grnpop(:,2),'bs','markersize',12)
plot(redpop(:,1),redpop(:,2),'bo','markersize',12)
plot(grnmean(:,1),grnmean(:,2),'gs','markersize',12,'MarkerFaceColor','g')
plot(redmean(:,1),redmean(:,2),'ro','markersize',12,'MarkerFaceColor','r')
plot(grnpts(:,1),grnpts(:,2),'g+','markersize',7)
plot(redpts(:,1),redpts(:,2),'rx','markersize',7)
hold off

% Produce a 2D plot for a range of ep and bc values
cvmat = zeros(length(epvec),length(bcvec));
errmat = zeros(length(epvec),length(bcvec));
k_ep = 1;
h_waitbar = waitbar(0,'Initializing');
for ep=epvec
    k_bc = 1;
    for bc=bcvec
        cvmat(k_ep,k_bc) = gqr_svmcv(cv_fold,train_data,train_class,ep,bc,low_rank);
        SVM = gqr_fitsvm(train_data,train_class,ep,bc,low_rank);
        errmat(k_ep,k_bc) = sum(test_class ~= SVM.eval(test_data));
        
        progress = floor(100*((k_ep-1)*length(bcvec)+k_bc)/(length(epvec)*length(bcvec)))/100;
        waitbar(progress,h_waitbar,sprintf('%d-fold CV, \\epsilon=%5.2f C=%5.2f',cv_fold,ep,bc))
        k_bc = k_bc + 1;
    end
    k_ep = k_ep + 1;
end

waitbar(1,h_waitbar,'Plotting')
[E,B] = meshgrid(epvec,bcvec);

h2 = figure;
h_ev = surf(E,B,cvmat');
set(h_ev,'edgecolor','none')
set(gca,'xscale','log')
set(gca,'yscale','log')
set(gca,'ytick',[1e-2,1e1,1e4])
xlabel('\epsilon')
ylabel('C')
zlim([.6,.75])
zlabel(sprintf('%d-fold CV residual',cv_fold))
shading interp
grid off
view([-.7,1,1])

h3 = figure;
h_err = surf(E,B,errmat');
set(h_err,'edgecolor','none')
set(gca,'xscale','log')
set(gca,'yscale','log')
set(gca,'ytick',[1e-2,1e1,1e4])
set(gca,'ztick',[0,10,20])
xlabel('\epsilon')
ylabel('C')
zlim([0,20])
zlabel(sprintf('missed classifications',cv_fold))
shading interp
grid off
view([-.7,1,1])

close(h_waitbar)